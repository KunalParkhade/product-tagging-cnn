{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-Irxgsta9WEzgimezoLxiR7z2Ou7aOGO",
      "authorship_tag": "ABX9TyOhxdm1pCc2788bn/0GM/cl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalParkhade/product-tagging-cnn/blob/main/Product_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQKday4Xvp50",
        "outputId": "0b9e3a92-2a88-4c04-c015-a8cf52c6a5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchmetrics import Accuracy, Precision, Recall"
      ],
      "metadata": {
        "id": "3KWNd-Y1v6je"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_data = datasets.FashionMNIST(root='./content/drive/MyDrive/Datasets/FashionMNIST', train=True, download=True,\n",
        "                                   transform = transforms.ToTensor())\n",
        "test_data = datasets.FashionMNIST(root='./content/drive/MyDrive/Datasets/FashionMNIST', train=False, download=True,\n",
        "                                   transform = transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Ts9rScwO0x",
        "outputId": "fa5540b1-7e0a-470e-b969-8fad13355617"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 17612279.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 343834.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6243628.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15216544.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./content/drive/MyDrive/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Define the CNN"
      ],
      "metadata": {
        "id": "3vyFp_kZw_wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GarmentClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GarmentClassifier, self).__init__()\n",
        "    # Convolutional Layer 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "    # ReLU activation function\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # Pooling layer 1\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "    # ReLU activation function\n",
        "    self.relu2 = nn.ReLU()\n",
        "    # Pooling layer 2\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(64 * 7 * 7, 1000)\n",
        "    # ReLU activation function\n",
        "    self.relu3 = nn.ReLU()\n",
        "\n",
        "    # Fully connected layer 2 (Output layer)\n",
        "    self.fc2 = nn.Linear(1000, 10)    # 10 classes for FashionMNIST\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Apply convolution 1, ReLU, and pooling 1\n",
        "    x = self.pool1(self.relu1(self.conv1(x)))\n",
        "    # Apply convolution 2, ReLU, and pooling 2\n",
        "    x = self.pool2(self.relu2(self.conv2(x)))\n",
        "    # Flatten the output\n",
        "    x = x.view(-1, 64 * 7 * 7)\n",
        "    # Apply fully connected layer 1 and ReLU\n",
        "    x = self.relu3(self.fc1(x))\n",
        "    # Apply fully connected layer 2 and ReLU\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "sf7tUpoNw5yp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chatgpt.com/share/6168aacb-45a0-4bfc-acf4-8293dc45f2dd"
      ],
      "metadata": {
        "id": "flg352ZdzSON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training the CNN"
      ],
      "metadata": {
        "id": "XNC1BQ5Q9gCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define the training loop:"
      ],
      "metadata": {
        "id": "TZzNGHJ89kjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function and optimizer\n",
        "model = GarmentClassifier()\n",
        "criterion = nn.CrossEntropyLoss() # Suitable loss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# DataLoader for batching\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "epochs = 2    # We limit epochs to 2 to keep runtime down\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, labels in train_loader:\n",
        "    optimizer.zero_grad()   # Zero the gradients\n",
        "    outputs = model(images)   # Forward pass\n",
        "    loss = criterion(outputs, labels)   # Calculate loss\n",
        "    loss.backward()   # Backward pass\n",
        "    optimizer.step()    # Update weights\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss:{running_loss/len(train_loader)}')"
      ],
      "metadata": {
        "id": "uzi0kzefzSkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9016a77-0ea4-4949-81d2-cca13e1a1183"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss:0.4139006641278389\n",
            "Epoch 2, Loss:0.26094082121782974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Testing the CNN\n",
        "Finally, let's test the model on the test dataset and store the predictions:"
      ],
      "metadata": {
        "id": "fKh7qrGkYVzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "model.eval()\n",
        "predictions = []\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    outputs = model(images)   # Forward pass\n",
        "    _, predicted = torch.max(outputs, 1)    # Get the index of the max log-probability\n",
        "    predictions.extend(predicted.cpu().numpy())\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy*100: .2f}%')"
      ],
      "metadata": {
        "id": "4Y9LGHYA-06y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b67596-3356-4687-afca-f2ec1ccf13d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  90.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZAolvGhaECf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}